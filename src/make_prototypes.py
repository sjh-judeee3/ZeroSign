import torch
import os
import json
from tqdm import tqdm
from dataset import SignLanguageDataset
from encoder import SLIPVideoEncoder
from models import HybridTemporalModel
from torchvision import transforms

# ì„¤ì •
LABEL_DIR = "/content/drive/MyDrive/Capstone/morpheme/01"
VIDEO_DIR = "/content/drive/MyDrive/Capstone/fin_videos_extracted"
MODEL_PATH = "/content/drive/MyDrive/Capstone/slip_protonet_final.pth"
SAVE_PATH = "/content/drive/MyDrive/Capstone/prototypes.pt"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

def create_prototypes():
    print(f"ğŸ› ï¸ í”„ë¡œí† íƒ€ì…(í´ë˜ìŠ¤ë³„ ê¸°ì¤€ì ) ìƒì„± ì‹œì‘... Device: {DEVICE}")

    # 1. ëª¨ë¸ ë¡œë“œ
    encoder = SLIPVideoEncoder(pretrained=False, embed_dim=512).to(DEVICE)
    temporal = HybridTemporalModel(input_dim=512, hidden_dim=512).to(DEVICE)
    
    checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
    encoder.load_state_dict(checkpoint['encoder'])
    temporal.load_state_dict(checkpoint['temporal'])
    
    encoder.eval()
    temporal.eval()

    # 2. ë°ì´í„°ì…‹ ë¡œë“œ (ì „ì²´ ë°ì´í„°ë¥¼ ë‹¤ ë´…ë‹ˆë‹¤)
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
    dataset = SignLanguageDataset(LABEL_DIR, VIDEO_DIR, transform=transform)

    # 3. í´ë˜ìŠ¤ë³„ ì„ë² ë”© ëª¨ìœ¼ê¸°
    class_embeddings = {} # { "ì•ˆë…•í•˜ì„¸ìš”": [tensor1, tensor2...], "ê°ì‚¬í•©ë‹ˆë‹¤": [...] }
    
    # ğŸŒŸğŸŒŸğŸŒŸ ì„¤ì • ë³€ìˆ˜ ğŸŒŸğŸŒŸğŸŒŸ
    MAX_SAMPLES_PER_CLASS = 10  # ê° í´ë˜ìŠ¤ë³„ë¡œ ìµœëŒ€ 10ê°œì˜ ì˜ìƒë§Œ ì‚¬ìš©
    
    # ğŸš¨ğŸš¨ğŸš¨ ë¹„ìƒ í…ŒìŠ¤íŠ¸ìš©: ì „ì²´ ìˆœíšŒ íšŸìˆ˜ë¥¼ ê°•ì œë¡œ ì œí•œí•©ë‹ˆë‹¤. ğŸš¨ğŸš¨ğŸš¨
    # 5013ê°œë¥¼ ëª¨ë‘ ëŒë©´ 4ì‹œê°„ì´ ê±¸ë¦¬ë¯€ë¡œ, ì¼ë‹¨ 500ê°œë§Œ ì²˜ë¦¬í•˜ê³  ì¢…ë£Œí•©ë‹ˆë‹¤.
    TOTAL_ITERATION_LIMIT = 500 # <--- ì´ ê°’ì„ ë³€ê²½í•˜ë©´ í…ŒìŠ¤íŠ¸ ì‹œê°„ì´ ë°”ë€ë‹ˆë‹¤.
    
    print(f"ğŸ“Š ë°ì´í„° ì„ë² ë”© ì¶”ì¶œ ì¤‘... (í´ë˜ìŠ¤ë³„ ìµœëŒ€ {MAX_SAMPLES_PER_CLASS}ê°œ / ì´ {TOTAL_ITERATION_LIMIT}íšŒ ì œí•œ)")
    
    with torch.no_grad():
        for i in tqdm(range(len(dataset))):
            
            # -----------------------------------------------
            # ğŸš¨ í•µì‹¬ ìˆ˜ì • 1: ì „ì²´ ìˆœíšŒ íšŸìˆ˜ ì œí•œ (ê°€ì¥ ë¹ ë¥´ê³  í™•ì‹¤í•œ ë‹¨ì¶• ë°©ë²•)
            if i >= TOTAL_ITERATION_LIMIT:
                print(f"\nğŸš¨ [ë¹„ìƒ í…ŒìŠ¤íŠ¸] ì´ ìˆœíšŒ íšŸìˆ˜ {TOTAL_ITERATION_LIMIT}íšŒ ë„ë‹¬. ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            # -----------------------------------------------
            
            try:
                img, label_path = dataset[i]
                
                # ë¼ë²¨ ì´ë¦„ ì¶”ì¶œ (JSON íŒŒì‹±)
                with open(label_path, 'r', encoding='utf-8') as f:
                    label_name = json.load(f)['data'][0]['attributes'][0]['name']
                
                # -----------------------------------------------
                # í•µì‹¬ ìˆ˜ì • 2: ì´ë¯¸ ì¶©ë¶„í•œ ìƒ˜í”Œì„ ëª¨ì•˜ë‹¤ë©´ ë¹„ë””ì˜¤ ë¡œë”© í›„ë¼ë„ ê±´ë„ˆë›°ê¸°
                if label_name in class_embeddings and len(class_embeddings[label_name]) >= MAX_SAMPLES_PER_CLASS:
                    continue
                # -----------------------------------------------

                img = img.unsqueeze(0).to(DEVICE) # (1, T, C, H, W)
                
                # íŠ¹ì§• ì¶”ì¶œ
                feats = encoder(img)
                emb = temporal(feats) # (1, 512)
                
                if label_name not in class_embeddings:
                    class_embeddings[label_name] = []
                class_embeddings[label_name].append(emb.cpu()) # CPUë¡œ ë‚´ë ¤ì„œ ì €ì¥ (ë©”ëª¨ë¦¬ ì ˆì•½)
                
            except Exception as e:
                continue

    # 4. í‰ê· (Prototype) ê³„ì‚°
    prototypes = {}
    print("ğŸ§® í´ë˜ìŠ¤ë³„ í‰ê·  ê³„ì‚° ì¤‘...")
    for label, emb_list in class_embeddings.items():
        # ìŠ¤íƒ í›„ í‰ê·  ê³„ì‚°
        emb_stack = torch.cat(emb_list, dim=0) # (N, 512)
        proto = emb_stack.mean(dim=0) # (512,) -> ì´ê²Œ ë°”ë¡œ ê·¸ í´ë˜ìŠ¤ì˜ ê¸°ì¤€ì !
        prototypes[label] = proto

    # 5. ì €ì¥
    torch.save(prototypes, SAVE_PATH)
    print(f"âœ… í”„ë¡œí† íƒ€ì… ì €ì¥ ì™„ë£Œ! ê²½ë¡œ: {SAVE_PATH}")
    print(f"ì´ {len(prototypes)}ê°œì˜ ìˆ˜ì–´ ë‹¨ì–´ ê¸°ì¤€ì ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    create_prototypes()