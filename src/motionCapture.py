import cv2
import numpy as np
import torch
import time
import os
import sounddevice as sd
from scipy.io.wavfile import write
from run_multimodal import main_run 

# --- ì„¤ì •ê°’ ---
FPS = 30
CAPTURE_DURATION = 3.0  # 3ì´ˆ ë™ì•ˆ ìˆ˜ì–´ ë™ì‘ ìº¡ì²˜
OUTPUT_VIDEO_PATH = "captured_video.pt"  # PyTorch í…ì„œ íŒŒì¼
OUTPUT_AUDIO_PATH = "captured_audio.wav" # ì˜¤ë””ì˜¤ íŒŒì¼

# âš ï¸ ì‚¬ìš©ìì˜ ìµœì¢… í•™ìŠµëœ ëª¨ë¸ ë° í”„ë¡œí† íƒ€ì… ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”.
MODEL_PATH = "slip_protonet_final.pth" 
PROTO_PATH = "prototypes.pt"

def record_audio(filename, duration, samplerate=44100):
    """ìŒì„±ì„ ë…¹ìŒí•˜ì—¬ WAV íŒŒì¼ë¡œ ì €ì¥"""
    print(f"\nğŸ¤ {duration}ì´ˆ ë™ì•ˆ ìŒì„± ë…¹ìŒ ì‹œì‘...")
    try:
        # ë…¹ìŒ ì‹œì‘
        recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')
        sd.wait()  # ë…¹ìŒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        write(filename, samplerate, recording)
        print(f"âœ… ìŒì„± ë…¹ìŒ ì™„ë£Œ: {filename}")
    except Exception as e:
        print(f"âŒ ìŒì„± ë…¹ìŒ ì‹¤íŒ¨ (ë§ˆì´í¬ ì„¤ì • ë° 'sounddevice' ê¶Œí•œ í™•ì¸ í•„ìš”): {e}")



def main_capture():
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    # ProtoNet ì¸í’‹ í˜•ì‹: T, 3, H, W (í”„ë ˆì„ ìˆ˜, ì±„ë„, ë†’ì´, ë„ˆë¹„)
    # SLIPì€ ë³´í†µ 224x224ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    TARGET_SIZE = (224, 224) 
    
    frames = []
    start_time = time.time()

    # 1. ì˜¤ë””ì˜¤ ë…¹ìŒì„ ë¹„ë™ê¸° ë˜ëŠ” ë³‘ë ¬ë¡œ ì‹œì‘ (ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ìˆœì°¨ ì²˜ë¦¬)
    # ì‹¤ì œ ì‹œì—° ì‹œì—ëŠ” ë³„ë„ ì“°ë ˆë“œë¡œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
    record_audio(OUTPUT_AUDIO_PATH, CAPTURE_DURATION) 
    
    print(f"ğŸ¬ {CAPTURE_DURATION}ì´ˆ ë™ì•ˆ ìˆ˜ì–´ ë™ì‘ ìº¡ì²˜ ì‹œì‘...")

    while time.time() - start_time < CAPTURE_DURATION:
        ret, frame = cap.read()
        if not ret: 
            break
        
        # ìº¡ì²˜ëœ í”„ë ˆì„ ì²˜ë¦¬ (ProtoNet í˜•ì‹ì— ë§ê²Œ)
        processed_frame = cv2.flip(frame, 1)  # ì¢Œìš° ë°˜ì „
        processed_frame = cv2.resize(processed_frame, TARGET_SIZE)
        # BGR -> RGB ë° ì •ê·œí™” (0-255 -> 0-1)
        processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0
        frames.append(processed_frame)

        cv2.putText(frame, f"Capturing: {len(frames)} frames", (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 200, 0), 3)
        cv2.imshow("Sign Capture", frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    print("âœ… ë¹„ë””ì˜¤ ìº¡ì²˜ ì™„ë£Œ.")

    if not frames:
        print("ìº¡ì²˜ëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    # 2. PyTorch í…ì„œë¡œ ë³€í™˜ (T, 3, H, W)
    video_np = np.stack(frames) # (T, H, W, 3)
    video_tensor = torch.from_numpy(video_np).permute(0, 3, 1, 2) # (T, 3, H, W)
    
    # 3. í…ì„œ ì €ì¥
    torch.save(video_tensor, OUTPUT_VIDEO_PATH)
    print(f"âœ… ë¹„ë””ì˜¤ í…ì„œ ì €ì¥ ì™„ë£Œ: {OUTPUT_VIDEO_PATH}")

    return OUTPUT_VIDEO_PATH, OUTPUT_AUDIO_PATH

if __name__ == '__main__':
    video_file, audio_file = main_capture()
    
    # -------------------------------------------------------------
    # ğŸŒŸğŸŒŸğŸŒŸ í†µí•© ì‹¤í–‰: ìº¡ì²˜ ì™„ë£Œ í›„ run_multimodalì˜ main_run í˜¸ì¶œ ğŸŒŸğŸŒŸğŸŒŸ
    # -------------------------------------------------------------
    if video_file and audio_file:
        print("\n==================================================")
        print("          âœ¨ ìº¡ì²˜ ì™„ë£Œ! ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ì‹¤í–‰...      ")
        print("==================================================")
        
        # motionCapture.pyê°€ run_multimodal.pyì˜ main_run í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤.
        main_run(MODEL_PATH, PROTO_PATH, video_file, audio_file)
    else:
        print("âŒ ìº¡ì²˜ ì˜¤ë¥˜ë¡œ ì¸í•´ ì¶”ë¡ ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")