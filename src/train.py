import os
import random
import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm

# âœ… ìš°ë¦¬ê°€ ë§Œë“  íŒŒì¼ë“¤ê³¼ ì •í™•íˆ ë§¤ì¹­ë˜ëŠ” ì„í¬íŠ¸
from dataset import SignLanguageDataset
from models import SLIP_ProtoNet

# ====================================================
# [ì„¤ì •] ê²½ë¡œë¥¼ ì •í™•íˆ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤!
# ====================================================
LABEL_DIR = "/content/drive/MyDrive/Capstone/ìˆ˜ì–´ì˜ìƒ2/labels_01"
VIDEO_DIR = "/content/drive/MyDrive/Capstone/fin_videos_extracted"

MAX_EPISODES = 100  # í…ŒìŠ¤íŠ¸ìš© (ë‚˜ì¤‘ì—” 10000 ì´ìƒìœ¼ë¡œ ëŠ˜ë¦¬ì„¸ìš”)
N_WAY = 5           # 5ì§€ ì„ ë‹¤
K_SHOT = 1          # ì •ë‹µì§€ 1ê°œ
Q_QUERY = 1         # ë¬¸ì œ 1ê°œ
LR = 0.001          # í•™ìŠµë¥ 

def train():
    # 1. ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU/MPS/CPU)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if torch.backends.mps.is_available(): device = torch.device("mps")
    print(f"ğŸš€ í•™ìŠµ ì‹œì‘! Device: {device}")

    # 2. ë°ì´í„°ì…‹ ì¤€ë¹„
    print("ğŸ“‚ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
    
    # [ìˆ˜ì •] label_dir, video_dir ë‘ ê°œë¥¼ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤!
    dataset = SignLanguageDataset(label_dir=LABEL_DIR, video_dir=VIDEO_DIR, transform=transform)
    
    # 3. Few-shotì„ ìœ„í•œ ë¼ë²¨ë³„ ì¸ë±ìŠ¤ ì •ë¦¬
    print("ğŸ“Š ë°ì´í„°ë¥¼ ë¼ë²¨ë³„ë¡œ ë¶„ë¥˜ ì¤‘... (ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤)")
    label_to_indices = {}
    
    # tqdmìœ¼ë¡œ ì§„í–‰ìƒí™© í‘œì‹œ
    for idx in tqdm(range(len(dataset))):
        try:
            # ë°ì´í„°ì…‹ ë‚´ë¶€ ë¦¬ìŠ¤íŠ¸ì— ì ‘ê·¼í•´ì„œ ë¼ë²¨ë§Œ ë¹ ë¥´ê²Œ ì¶”ì¶œ
            # (__getitem__ì„ ì“°ë©´ ì˜ìƒì„ ì½ì–´ì„œ ëŠë ¤ì§ -> ìµœì í™”)
            import json
            with open(dataset.json_paths[idx], 'r', encoding='utf-8') as f:
                meta = json.load(f)
                label = meta['data'][0]['attributes'][0]['name']
            
            if label not in label_to_indices:
                label_to_indices[label] = []
            label_to_indices[label].append(idx)
        except:
            continue

    # ë°ì´í„°ê°€ ë„ˆë¬´ ì ì€ í´ë˜ìŠ¤ ì œì™¸
    min_samples = K_SHOT + Q_QUERY
    valid_labels = [lbl for lbl, idxs in label_to_indices.items() if len(idxs) >= min_samples]
    print(f"âœ… í•™ìŠµ ê°€ëŠ¥ ë‹¨ì–´ ìˆ˜: {len(valid_labels)}ê°œ (ì´ ë¼ë²¨ {len(label_to_indices)}ê°œ ì¤‘)")

    if len(valid_labels) < N_WAY:
        print(f"âŒ ì—ëŸ¬: N_WAY({N_WAY})ë³´ë‹¤ í•™ìŠµ ê°€ëŠ¥í•œ ë‹¨ì–´ ìˆ˜ê°€ ì ìŠµë‹ˆë‹¤.")
        return

    # 4. ëª¨ë¸ ì¤€ë¹„ (SLIP_ProtoNet í•˜ë‚˜ë¡œ í•´ê²°)
    model = SLIP_ProtoNet(pretrained=True).to(device)
    optimizer = optim.Adam(model.parameters(), lr=LR)
    
    model.train()

    # 5. í•™ìŠµ ë£¨í”„ (Episode Training)
    print("ğŸ”¥ Training Loop Start...")
    for episode in range(MAX_EPISODES):
        optimizer.zero_grad()
        
        # (1) ì´ë²ˆ ì—í”¼ì†Œë“œìš© ìƒ˜í”Œë§
        sampled_classes = random.sample(valid_labels, N_WAY)
        
        support_imgs = []
        query_imgs = []
        target_labels = [] 

        for i, class_label in enumerate(sampled_classes):
            indices = label_to_indices[class_label]
            # ì¤‘ë³µ ì—†ì´ K+Qê°œ ë½‘ê¸°
            selected_indices = random.sample(indices, K_SHOT + Q_QUERY)
            
            # Support Set
            for idx in selected_indices[:K_SHOT]:
                img, _ = dataset[idx]
                support_imgs.append(img)
                
            # Query Set
            for idx in selected_indices[K_SHOT:]:
                img, _ = dataset[idx]
                query_imgs.append(img)
                target_labels.append(i) # 0~4 ì‚¬ì´ ì •ë‹µ ë¼ë²¨

        # í…ì„œ í•©ì¹˜ê¸° & ì´ë™
        support_imgs = torch.stack(support_imgs).to(device)
        query_imgs = torch.stack(query_imgs).to(device)
        target_labels = torch.tensor(target_labels).to(device)

        # (2) ëª¨ë¸ ì˜ˆì¸¡ (Forward)
        # SLIP_ProtoNetì´ ë‚´ë¶€ì—ì„œ ì¸ì½”ë”© -> í”„ë¡œí† íƒ€ì… ìƒì„± -> ê±°ë¦¬ ê³„ì‚°ê¹Œì§€ ë‹¤ í•´ì¤ë‹ˆë‹¤.
        log_probs = model(support_imgs, query_imgs, N_WAY, K_SHOT)
        
        # (3) Loss ê³„ì‚° & ì—…ë°ì´íŠ¸
        loss = torch.nn.functional.nll_loss(log_probs, target_labels)
        loss.backward()
        optimizer.step()

        # (4) ì •í™•ë„ ì¶œë ¥
        y_pred = log_probs.argmax(1)
        acc = (y_pred == target_labels).float().mean()

        if (episode + 1) % 10 == 0:
            print(f"Episode [{episode+1}/{MAX_EPISODES}] Loss: {loss.item():.4f} | Acc: {acc.item()*100:.2f}%")

    print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    # ëª¨ë¸ ì €ì¥
    torch.save(model.state_dict(), "slip_protonet_final.pth")

if __name__ == "__main__":
    train()